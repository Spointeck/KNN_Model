{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "X_numeric = df[num_pred]\n",
    "X_categorical = df[cat_pred]\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "X_categorical_encoded = encoder.fit_transform(X_categorical)\n",
    "X = np.concatenate([X_numeric, X_categorical_encoded.toarray()], axis=1)\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Training the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Calculating accuracy\n",
    "accuracy_LG = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy_LG)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(\"ROC AUC Score:\", roc_auc)\n",
    "\n",
    "# df['readmitted'] = df['readmitted'].astype(int)\n",
    "\n",
    "# # Now you can perform the comparison\n",
    "# df_filtered = df[df['readmitted'] >= 10]\n",
    "\n",
    "# X_train_array = np.asarray(X_train)\n",
    "# y_train_array = np.asarray(y_train)\n",
    "\n",
    "# # Fit logistic regression model\n",
    "# logit_model = sm.Logit(y_train_array, sm.add_constant(X_train_array))\n",
    "# logit_result = logit_model.fit()\n",
    "\n",
    "# # Print summary\n",
    "# print(logit_result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled = StandardScaler().fit_transform(df[num_cols])\n",
    "data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: K-Means Clustering\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is your DataFrame with predictors\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Perform K-Means clustering\n",
    "kmeans = KMeans(n_clusters=3)  # You can adjust the number of clusters as needed\n",
    "kmeans.fit(X_scaled)\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "# Visualize the clusters (assuming you have only two features for simplicity)\n",
    "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=cluster_labels, cmap='viridis')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('K-Means Clustering')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "wcss=[]\n",
    "for i in range(1,11):\n",
    "    kmeans=KMeans(n_clusters=i,init='random',random_state=42)\n",
    "    kmeans.fit(data_scaled)\n",
    "    wcss.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,11),wcss,'bx-')\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('No of Clusters')\n",
    "plt.ylabel('wcss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(data_scaled)\n",
    "\n",
    "sample_silhouette_values = silhouette_samples(data_scaled,clusters)\n",
    "range_n_clusters = list(range(2,6))\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    clusterer = KMeans(n_clusters=n_clusters)\n",
    "    preds = clusterer.fit_predict(data_scaled)\n",
    "    centers = clusterer.cluster_centers_\n",
    "    score = silhouette_score(data_scaled,preds)\n",
    "    print('For n_clusters = {},silhouette score is {})'.format(n_clusters,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = kmeans.fit_predict(data_scaled)\n",
    "Final_Clusters = clusters+1\n",
    "cluster = list(Final_Clusters)\n",
    "df['cluster'] = cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "X = np.random.rand(100, 2)  \n",
    "\n",
    "k = 3\n",
    "\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "\n",
    "kmeans.fit(X)\n",
    "\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Print cluster centroids and labels\n",
    "print(\"Cluster Centroids:\")\n",
    "print(centroids)\n",
    "print(\"\\nCluster Labels:\")\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming df is your DataFrame with predictors and target variable\n",
    "num_pred = ['time_in_hospital' , 'num_procedures' , 'num_medications']\n",
    "cat_pred = ['race' , 'gender' , 'age' , 'insulin' , 'change']\n",
    "target = ['readmitted']\n",
    "\n",
    "X_numeric = df[num_pred]\n",
    "X_categorical = df[cat_pred]\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "X_categorical_encoded = encoder.fit_transform(X_categorical)\n",
    "X = np.concatenate([X_numeric, X_categorical_encoded.toarray()], axis=1)\n",
    "y = df[target]\n",
    "\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Instantiate the KNN classifier with a specified number of neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit the model to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, cmap=\"Blues\", fmt=\"d\", cbar=False)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
